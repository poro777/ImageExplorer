import json
import os
import pathlib
from pymilvus import MilvusClient
from pymilvus import (
    MilvusClient, DataType, Function, FunctionType
)
from pymilvus import Collection, connections
from pymilvus import AnnSearchRequest
from pymilvus import RRFRanker, WeightedRanker
import numpy as np
from indexer import genai_api, text_embed, clip_embed

from PIL import Image as ImageLoader
from io import BytesIO

TEXT_FEATURE_DIM = 256
IMAGE_FEATURE_DIM = 512


milvus_host = os.getenv("MILVUS_HOST", "localhost")
mulvus_port = os.getenv("MILVUS_PORT", "19530")
milvus_token = os.getenv("MILVUS_TOKEN", "root:Milvus")
milvus_uri = os.getenv("MILVUS_URI", "http://localhost:19530")

COLLECTION_NAME = "my_collection"

FIELD_ID = "id"
FIELD_TEXT = "text" # raw text
FIELD_TEXT_SPARSE = "text_sparse" # BM 25

FIELD_TEXT_DENSE = "text_dense" # text 2 vec
FIELD_IMAGE_DENSE = "image_dense" # clip embedding

FIELD_CN_TEXT = "cn_text" # raw text for chinese analyzer
FIELD_CN_TEXT_SPARSE = "cn_text_sparse" # BM 25



def is_collection_exist(collection: str):
    client = MilvusClient(uri=milvus_uri, token=milvus_token)  
    return client.has_collection(collection_name=collection)


def create_embed_db(collection: str):
    client = MilvusClient(uri=milvus_uri, token=milvus_token)  

    schema = MilvusClient.create_schema(auto_id=False)

    cn_analyzer_params = {
        "tokenizer": "jieba",
        "filter": [
            "cnalphanumonly",
            "lowercase",
            {
                "type": "stemmer",
                "language": "english"
            },
            {
                "type": "stop", # Specifies the filter type as stop
                "stop_words": ["_english_"], # Defines custom stop words and includes the English stop word list
            }
        ]
    }

    schema.add_field(field_name=FIELD_ID, datatype=DataType.INT64, is_primary=True, description="product id")
    
    schema.add_field(field_name=FIELD_TEXT, datatype=DataType.VARCHAR, max_length=2048, enable_analyzer=True,
                      description="raw text of product description")
    
    schema.add_field(field_name=FIELD_TEXT_DENSE, datatype=DataType.FLOAT_VECTOR, dim=TEXT_FEATURE_DIM, description="text dense embedding")
    
    schema.add_field(field_name=FIELD_TEXT_SPARSE, datatype=DataType.SPARSE_FLOAT_VECTOR, 
                     description="text sparse embedding auto-generated by the built-in BM25 function")

    schema.add_field(field_name=FIELD_IMAGE_DENSE, datatype=DataType.FLOAT_VECTOR, dim=IMAGE_FEATURE_DIM, description="image dense embedding")

    schema.add_field(field_name=FIELD_CN_TEXT, datatype=DataType.VARCHAR, max_length=2048, enable_analyzer=True, analyzer_params=cn_analyzer_params, 
                      description="raw text of product description for chinese analyzer")
        
    schema.add_field(field_name=FIELD_CN_TEXT_SPARSE, datatype=DataType.SPARSE_FLOAT_VECTOR, 
                     description="text sparse embedding auto-generated by the built-in BM25 function for chinese tokens")

    bm25_function = Function(
        name="text_bm25_emb",
        input_field_names=[FIELD_TEXT],
        output_field_names=[FIELD_TEXT_SPARSE],
        function_type=FunctionType.BM25,
    )
    schema.add_function(bm25_function)

    cn_bm25_function = Function(
        name="cm_text_bm25_emb",
        input_field_names=[FIELD_CN_TEXT],
        output_field_names=[FIELD_CN_TEXT_SPARSE],
        function_type=FunctionType.BM25,
    )
    schema.add_function(cn_bm25_function)

    index_params = client.prepare_index_params()

    index_params.add_index(
        field_name=FIELD_TEXT_DENSE,
        index_name=FIELD_TEXT_DENSE + "_index",
        index_type="AUTOINDEX",
        metric_type="IP"
    )

    index_params.add_index(
        field_name=FIELD_TEXT_SPARSE,
        index_name=FIELD_TEXT_SPARSE + "_index",
        index_type="SPARSE_INVERTED_INDEX",
        metric_type="BM25",
        params={"inverted_index_algo": "DAAT_MAXSCORE"}, # or "DAAT_WAND" or "TAAT_NAIVE"
    )
    index_params.add_index(
        field_name=FIELD_CN_TEXT_SPARSE,
        index_name=FIELD_CN_TEXT_SPARSE + "_index",
        index_type="SPARSE_INVERTED_INDEX",
        metric_type="BM25",
        params={"inverted_index_algo": "DAAT_MAXSCORE"}, # or "DAAT_WAND" or "TAAT_NAIVE"
    )

    index_params.add_index(
        field_name=FIELD_IMAGE_DENSE,
        index_name=FIELD_IMAGE_DENSE + "_index",
        index_type="AUTOINDEX",
        metric_type="IP"
    )

    if client.has_collection(collection_name=collection):
        client.drop_collection(collection_name=collection)

    client.create_collection(
        collection_name=collection,
        schema=schema,
        index_params=index_params
    )

def delete_empty_data():
    client = MilvusClient(uri=milvus_uri, token=milvus_token)  
    connections.connect(alias="default", host=milvus_host, port=mulvus_port)

    # Step 2: Load the collection
    collection = Collection(COLLECTION_NAME)
    collection.load()
    results = collection.query(
        expr="",  # empty expr returns all data
        output_fields=[FIELD_ID, FIELD_TEXT],  # list all text fields you want to extract
        limit=100
    )

    ids = [result[FIELD_ID] for result in results if len(result[FIELD_TEXT]) == 0]
    if len(ids) == 0:
        return

    res = client.delete(
        collection_name=COLLECTION_NAME,
        # highlight-next-line
        ids=ids
    )



def query_one(collection: str, top_k:int = 10, query_text: str = "", query_text_embed = None, query_clip_text_embed =  None, query_clip_image_embed =  None, 
                  use_text_embed = True, use_bm25 = True, use_joint_embed = True, use_image_embed = False
                  ):
    '''
    - use_text_embed : text2vector
    - use_bm25 : BM25 exact match
    - use_joint_embed : given clip text embedding query image embedding in dataset
    - use_image_embed : given image embedding query image embedding in dataset
    '''
    client = MilvusClient(uri=milvus_uri, token=milvus_token)  
    
    reqs = []
    weight = []

    if use_text_embed and query_text_embed is not None:
        search_param = {
            "data": [query_text_embed],
            "anns_field": FIELD_TEXT_DENSE,
            "param": {"nprobe": 10},
            "limit": 10
        }
        req = AnnSearchRequest(**search_param)
        reqs.append(req)
        weight.append(1.0)

    if use_bm25:
        search_param = {
            "data": [query_text],
            "anns_field": FIELD_TEXT_SPARSE,
            "param": {"drop_ratio_search": 0.0},
            "limit": 10
        }
        req1 = AnnSearchRequest(**search_param)

        search_param = {
            "data": [query_text],
            "anns_field": FIELD_CN_TEXT_SPARSE,
            "param": {"drop_ratio_search": 0.0},
            "limit": 10
        }
        req2 = AnnSearchRequest(**search_param)

        reqs += [req1, req2]
        weight += [1.0, 1.0]

    if use_joint_embed and query_clip_text_embed is not None:
        # query joint embedding
        search_param = {
            "data": [query_clip_text_embed],
            "anns_field": FIELD_IMAGE_DENSE,
            "param": {"nprobe": 10},
            "limit": 10
        }
        req = AnnSearchRequest(**search_param)
        reqs.append(req)
        weight.append(1.0)

    if use_image_embed and query_clip_image_embed is not None:
        # query joint embedding
        search_param = {
            "data": [query_clip_image_embed],
            "anns_field": FIELD_IMAGE_DENSE,
            "param": {"nprobe": 10},
            "limit": 10
        }
        req = AnnSearchRequest(**search_param)
        reqs.append(req)
        weight.append(1.0)

    if len(reqs) == 0:
        return []

    ranker = RRFRanker(60)
    res = client.hybrid_search(
        collection_name=collection,
        reqs=reqs,
        ranker=ranker,
        output_fields=[],
        limit=top_k
    )[0]

    return [{FIELD_ID: hit[FIELD_ID], "distance": hit["distance"]} 
            for hit in res]

def insert_one(collection: str, id = None, text= None, text_dense= None, image_dense= None):
    client = MilvusClient(uri=milvus_uri, token=milvus_token)  

    if id is None:
        return False
    if text is None:
        text = ""
    if text_dense is None:
        text_dense = np.zeros(TEXT_FEATURE_DIM).tolist()
    if image_dense is None:
        image_dense = np.zeros(IMAGE_FEATURE_DIM).tolist()

    data=[
        {
            FIELD_ID: id,
            FIELD_TEXT: text,
            FIELD_CN_TEXT: text,
            FIELD_TEXT_DENSE: text_dense,
            FIELD_IMAGE_DENSE: image_dense
        }
    ]

    try:
        res = client.insert(
            collection_name=collection,
            data=data
        )
        return True
    except Exception as e:
        print(e)
        return False
    

def delete_one(collection: str, id):
    client = MilvusClient(uri=milvus_uri, token=milvus_token)  

    try:
        res = client.delete(
            collection_name=collection,
            ids=[id]
        )
        return True
    except Exception as e:
        print(e)
        return False
    

def list_data(collection: str):
    connections.connect(alias="default", host=milvus_host, port=mulvus_port)

    collection = Collection(collection)
    collection.load()

    results = collection.query(
        expr="",  # empty expr returns all data
        output_fields=[FIELD_ID, FIELD_TEXT],  # list all text fields you want to extract
        limit=100
    )

    return [ {FIELD_ID: tag[FIELD_ID],FIELD_TEXT: tag[FIELD_TEXT]} 
            for tag in results]


def dump_json_data(collection: str, output_path: str = "data.json"):
    connections.connect(alias="default", host=milvus_host, port=mulvus_port)

    collection = Collection(COLLECTION_NAME)
    collection.load()

    # Replace 'text_field' with the actual name of the field storing text
    results = collection.query(
        expr="",  # empty expr returns all data
        output_fields=[FIELD_ID, FIELD_TEXT],  # list all text fields you want to extract
        limit=100
    )

    print(len(results))
    r = {result[FIELD_ID]: result[FIELD_TEXT] for result in results}
    
    with open(output_path, "w") as f:
        json.dump(r, f, indent=4)  # optional: indent for readability

def insert_json_data(file_path: str = "data.json"):
    import requests
    with open(file_path, "r") as f:
        data = json.load(f)
        
    for k, v in data.items():
        print(k)
        requests.post('http://127.0.0.1:5000/insert', data = {FIELD_ID : k})



def insert_image(id: int, file_path:str, image: ImageLoader):
    file_path: pathlib.Path = pathlib.Path(file_path).resolve()

    image_format = image.format.lower()

    # Convert to BytesIO
    buffer = BytesIO()
    image.save(buffer, format=image_format) 
    buffer.seek(0)  # rewind to the start of the stream

    text = genai_api.explainImage(file_path.name, image_format, buffer)
    text_features = text_embed.get_text_embed_doc(text)
    image_features = clip_embed.get_image_embed(image)

    successed = insert_one(COLLECTION_NAME, id, text, text_features, image_features)
    return successed


if __name__ == "__main__":
    pass