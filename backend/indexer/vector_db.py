import json
import os
import pathlib
from typing import List, Optional
from pymilvus import MilvusClient
from pymilvus import (
    MilvusClient, DataType, Function, FunctionType
)
from pymilvus import Collection, connections
from pymilvus import AnnSearchRequest
from pymilvus import RRFRanker, WeightedRanker
import numpy as np
from indexer import genai_api, text_embed, clip_embed

from PIL.ImageFile import ImageFile
from io import BytesIO
from contextlib import contextmanager

TEXT_FEATURE_DIM = 256
IMAGE_FEATURE_DIM = 512


milvus_host = os.getenv("MILVUS_HOST", "localhost")
mulvus_port = os.getenv("MILVUS_PORT", "19530")
milvus_token = os.getenv("MILVUS_TOKEN", "root:Milvus")
milvus_uri = os.getenv("MILVUS_URI", "http://localhost:19530")

COLLECTION_NAME = "my_collection"

FIELD_ID = "id"
FIELD_TEXT = "text" # raw text
FIELD_TEXT_SPARSE = "text_sparse" # BM 25

FIELD_TEXT_DENSE = "text_dense" # text 2 vec
FIELD_IMAGE_DENSE = "image_dense" # clip embedding

FIELD_CN_TEXT = "cn_text" # raw text for chinese analyzer
FIELD_CN_TEXT_SPARSE = "cn_text_sparse" # BM 25

@contextmanager
def getClient():
    """
    Get a Milvus client instance.
    """
    try:
        client = MilvusClient(uri=milvus_uri, token=milvus_token)
        yield client
    finally:
        #client.close()
        pass

    
    

def is_collection_exist(collection: str):
    with getClient() as client:
        result = client.has_collection(collection_name=collection)

    return result

def is_partition_exist(collection:str, partition_name: str):
    with getClient() as client:
        result = client.has_partition(
            collection_name=collection,
            partition_name=partition_name
        )

    return result
    
def create_partition(collection:str,  new_partition_name: str):
    if is_partition_exist(collection, new_partition_name):
        return
    
    with getClient() as client:
        client.create_partition(
            collection_name = collection,
            partition_name = new_partition_name
        )

def create_embed_db(collection: str):
    schema = MilvusClient.create_schema(auto_id=False)

    cn_analyzer_params = {
        "tokenizer": "jieba",
        "filter": [
            "cnalphanumonly",
            "lowercase",
            {
                "type": "stemmer",
                "language": "english"
            },
            {
                "type": "stop", # Specifies the filter type as stop
                "stop_words": ["_english_"], # Defines custom stop words and includes the English stop word list
            }
        ]
    }

    schema.add_field(field_name=FIELD_ID, datatype=DataType.INT64, is_primary=True, description="product id")
    
    schema.add_field(field_name=FIELD_TEXT, datatype=DataType.VARCHAR, max_length=2048, enable_analyzer=True,
                      description="raw text of product description")
    
    schema.add_field(field_name=FIELD_TEXT_DENSE, datatype=DataType.FLOAT_VECTOR, dim=TEXT_FEATURE_DIM, description="text dense embedding")
    
    schema.add_field(field_name=FIELD_TEXT_SPARSE, datatype=DataType.SPARSE_FLOAT_VECTOR, 
                     description="text sparse embedding auto-generated by the built-in BM25 function")

    schema.add_field(field_name=FIELD_IMAGE_DENSE, datatype=DataType.FLOAT_VECTOR, dim=IMAGE_FEATURE_DIM, description="image dense embedding")

    schema.add_field(field_name=FIELD_CN_TEXT, datatype=DataType.VARCHAR, max_length=2048, enable_analyzer=True, analyzer_params=cn_analyzer_params, 
                      description="raw text of product description for chinese analyzer")
        
    schema.add_field(field_name=FIELD_CN_TEXT_SPARSE, datatype=DataType.SPARSE_FLOAT_VECTOR, 
                     description="text sparse embedding auto-generated by the built-in BM25 function for chinese tokens")

    bm25_function = Function(
        name="text_bm25_emb",
        input_field_names=[FIELD_TEXT],
        output_field_names=[FIELD_TEXT_SPARSE],
        function_type=FunctionType.BM25,
    )
    schema.add_function(bm25_function)

    cn_bm25_function = Function(
        name="cm_text_bm25_emb",
        input_field_names=[FIELD_CN_TEXT],
        output_field_names=[FIELD_CN_TEXT_SPARSE],
        function_type=FunctionType.BM25,
    )
    schema.add_function(cn_bm25_function)

    with getClient() as client:
        index_params = client.prepare_index_params()

        index_params.add_index(
            field_name=FIELD_TEXT_DENSE,
            index_name=FIELD_TEXT_DENSE + "_index",
            index_type="AUTOINDEX",
            metric_type="IP"
        )

        index_params.add_index(
            field_name=FIELD_TEXT_SPARSE,
            index_name=FIELD_TEXT_SPARSE + "_index",
            index_type="SPARSE_INVERTED_INDEX",
            metric_type="BM25",
            params={"inverted_index_algo": "DAAT_MAXSCORE"}, # or "DAAT_WAND" or "TAAT_NAIVE"
        )
        index_params.add_index(
            field_name=FIELD_CN_TEXT_SPARSE,
            index_name=FIELD_CN_TEXT_SPARSE + "_index",
            index_type="SPARSE_INVERTED_INDEX",
            metric_type="BM25",
            params={"inverted_index_algo": "DAAT_MAXSCORE"}, # or "DAAT_WAND" or "TAAT_NAIVE"
        )

        index_params.add_index(
            field_name=FIELD_IMAGE_DENSE,
            index_name=FIELD_IMAGE_DENSE + "_index",
            index_type="AUTOINDEX",
            metric_type="IP"
        )

        if client.has_collection(collection_name=collection):
            client.drop_collection(collection_name=collection)

        client.create_collection(
            collection_name=collection,
            schema=schema,
            index_params=index_params
        )

def delete_empty_data(collection: str):
    connections.connect(alias="default", host=milvus_host, port=mulvus_port)

    # Step 2: Load the collection
    collection = Collection(collection)
    collection.load()
    results = collection.query(
        expr="",  # empty expr returns all data
        output_fields=[FIELD_ID, FIELD_TEXT],  # list all text fields you want to extract
        limit=100
    )

    ids = [result[FIELD_ID] for result in results if len(result[FIELD_TEXT]) == 0]
    if len(ids) == 0:
        return
    
    with getClient() as client:
        res = client.delete(
            collection_name=collection,
            # highlight-next-line
            ids=ids
        )



def query(collection: str, partitions:Optional[List[str]] ,top_k:int = 10, query_text: str = "", query_text_embed = None, query_clip_text_embed =  None, query_clip_image_embed =  None, 
                  use_text_embed = True, use_bm25 = True, use_joint_embed = True, use_image_embed = False
                  ):
    '''
    - use_text_embed : text2vector
    - use_bm25 : BM25 exact match
    - use_joint_embed : given clip text embedding query image embedding in dataset
    - use_image_embed : given image embedding query image embedding in dataset
    '''

    reqs = []
    weight = []

    if use_text_embed and query_text_embed is not None:
        search_param = {
            "data": [query_text_embed],
            "anns_field": FIELD_TEXT_DENSE,
            "param": {"nprobe": 10},
            "limit": 10
        }
        req = AnnSearchRequest(**search_param)
        reqs.append(req)
        weight.append(1.0)

    if use_bm25:
        search_param = {
            "data": [query_text],
            "anns_field": FIELD_TEXT_SPARSE,
            "param": {"drop_ratio_search": 0.0},
            "limit": 10
        }
        req1 = AnnSearchRequest(**search_param)

        search_param = {
            "data": [query_text],
            "anns_field": FIELD_CN_TEXT_SPARSE,
            "param": {"drop_ratio_search": 0.0},
            "limit": 10
        }
        req2 = AnnSearchRequest(**search_param)

        reqs += [req1, req2]
        weight += [1.0, 1.0]

    if use_joint_embed and query_clip_text_embed is not None:
        # query joint embedding
        search_param = {
            "data": [query_clip_text_embed],
            "anns_field": FIELD_IMAGE_DENSE,
            "param": {"nprobe": 10},
            "limit": 10
        }
        req = AnnSearchRequest(**search_param)
        reqs.append(req)
        weight.append(1.0)

    if use_image_embed and query_clip_image_embed is not None:
        # query joint embedding
        search_param = {
            "data": [query_clip_image_embed],
            "anns_field": FIELD_IMAGE_DENSE,
            "param": {"nprobe": 10},
            "limit": 10
        }
        req = AnnSearchRequest(**search_param)
        reqs.append(req)
        weight.append(1.0)

    if len(reqs) == 0:
        return []
    
    with getClient() as client:
        ranker = RRFRanker(60)
        res = client.hybrid_search(
            collection_name=collection,
            partition_names=partitions,
            reqs=reqs,
            ranker=ranker,
            output_fields=[],
            limit=top_k
        )[0]

    return [{FIELD_ID: hit[FIELD_ID], "distance": hit["distance"]} 
            for hit in res]

def insert_one(collection: str, partition:str, id = None, text= None, text_dense= None, image_dense= None) -> bool:
    

    if is_partition_exist(collection, partition) == False:
        create_partition(collection, partition)

    if id is None:
        return False
    if text is None:
        text = ""
    if text_dense is None:
        text_dense = np.zeros(TEXT_FEATURE_DIM).tolist()
    if image_dense is None:
        image_dense = np.zeros(IMAGE_FEATURE_DIM).tolist()

    data=[
        {
            FIELD_ID: id,
            FIELD_TEXT: text,
            FIELD_CN_TEXT: text,
            FIELD_TEXT_DENSE: text_dense,
            FIELD_IMAGE_DENSE: image_dense
        }
    ]

    try:
        with getClient() as client:
            res = client.upsert(
                collection_name=collection,
                partition_name=partition,
                data=data
            )
        return True
    except Exception as e:
        print(e)
        return False

def delete_by_list(collection: str, ids: List[int]):
    
    if len(ids) == 0:
        return True
    
    try:
        with getClient() as client:
            res = client.delete(
                collection_name=collection,
                ids=ids
            )
        return True
    except Exception as e:
        print(e)
        return False

def delete_one(collection: str, id):
    return delete_by_list(collection, [id])

    
def list_data(collection: str, partitions: Optional[List[str]] = None):
    '''return { id : text, ...}'''

    with getClient() as client:
        results = client.query(
            collection_name=collection,  # empty expr returns all data
            filter="",  # empty expr returns all data
            output_fields=[FIELD_ID, FIELD_TEXT],  # list all text fields you want to extract
            limit=100,
            partition_names=partitions
        )

    return {tag[FIELD_ID]: tag[FIELD_TEXT] for tag in results} 
            


def dump_json_data(collection: str, output_path: str = "data.json"):
    connections.connect(alias="default", host=milvus_host, port=mulvus_port)

    collection = Collection(COLLECTION_NAME)
    collection.load()

    # Replace 'text_field' with the actual name of the field storing text
    results = collection.query(
        expr="",  # empty expr returns all data
        output_fields=[FIELD_ID, FIELD_TEXT],  # list all text fields you want to extract
        limit=100
    )

    print(len(results))
    r = {result[FIELD_ID]: result[FIELD_TEXT] for result in results}
    
    with open(output_path, "w") as f:
        json.dump(r, f, indent=4)  # optional: indent for readability

def insert_json_data(file_path: str = "data.json"):
    import requests
    with open(file_path, "r") as f:
        data = json.load(f)
        
    for k, v in data.items():
        print(k)
        requests.post('http://127.0.0.1:5000/insert', data = {FIELD_ID : k})

def change_partition(collection: str, id: int, new_partition: str):
    '''
    change partition of a given id
    '''
    try:
        with getClient() as client:
            image = client.get(
                collection_name=collection,
                ids=id,
                output_fields=[FIELD_ID, FIELD_TEXT, FIELD_TEXT_DENSE, FIELD_IMAGE_DENSE]
            )[0]

        if delete_one(collection, id) == False:
            print(f"Error deleting image {id}  during partition change")
            return False
        
        if insert_one(collection, new_partition, id, image[FIELD_TEXT], image[FIELD_TEXT_DENSE], image[FIELD_IMAGE_DENSE]) == False:
            print(f"Error inserting image {id} to partition {new_partition} during partition change")
            return False
        
        return True
    except Exception as e:
        print(e)
        return False


def insert_image(collection: str, id: int, filename:str, image: ImageFile, partition_id: Optional[int] = None) -> bool:
    image_format = image.format.lower()

    # Convert to BytesIO
    buffer = BytesIO()
    image.save(buffer, format=image_format) 
    buffer.seek(0)  # rewind to the start of the stream

    text = genai_api.explainImage(filename, image_format, buffer)
    text_features = text_embed.get_text_embed_doc(text)
    image_features = clip_embed.get_image_embed(image)

    partition = str(partition_id) if partition_id is not None else "_default"
    successed = insert_one(collection, partition, id, text, text_features, image_features)
    return successed

def query_images_by_text(collection: str, top_k:int, text: str, use_text_embed: bool, use_bm25: bool, use_joint_embed: bool, partition_id: Optional[int] = None):
    '''return [{"id":int, "distance":float}, ...]'''
    clip_text_features = clip_embed.get_text_embed(text)
    text_features = text_embed.get_text_embed_query(text)
    use_image_embed = False
    clip_image_features = None

    partitions = [str(partition_id)] if partition_id is not None else None
    results = query(collection, partitions, top_k, text, text_features, clip_text_features, clip_image_features, 
                                use_text_embed, use_bm25, use_joint_embed, use_image_embed )

    return results



    
if __name__ == "__main__":
    pass